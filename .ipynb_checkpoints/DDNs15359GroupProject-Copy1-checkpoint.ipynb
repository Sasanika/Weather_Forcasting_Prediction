{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "V_-ytJNavOQP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SnLA9bzByyaq"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/weatherHistory.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15104\\727966913.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mweather_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/weatherHistory.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/weatherHistory.csv'"
     ]
    }
   ],
   "source": [
    "weather_hist = pd.read_csv('/content/weatherHistory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07SFhxQTy58Q",
    "outputId": "cea08f64-a52c-406b-9b42-e868a7defe3b"
   },
   "outputs": [],
   "source": [
    "weather_hist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "Br5siQoly-zw",
    "outputId": "fa735802-2397-4deb-92b7-30634d62c887"
   },
   "outputs": [],
   "source": [
    "weather_hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "uZmlDMeazRSQ",
    "outputId": "282a88e8-f5d2-4ab0-ecba-09822fc784f3"
   },
   "outputs": [],
   "source": [
    "weather_hist.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtxD5USVzW3I",
    "outputId": "58f4d172-8523-4434-80b1-82f4ed7bc53e"
   },
   "outputs": [],
   "source": [
    "print(\"Number of Columns in the Weather History Data frame:\", weather_hist.shape[1])\n",
    "print(\"Number of records in the Weather History data frame:\", weather_hist.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QHVd-RlPzdDP",
    "outputId": "bab5fa6c-593d-4744-c8c9-00bb68eb061b"
   },
   "outputs": [],
   "source": [
    "print (\"Unique values are:\\n\",weather_hist.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tUfn5y8gzivw",
    "outputId": "e30d79a7-8eac-4070-f674-587b58b90d8f"
   },
   "outputs": [],
   "source": [
    "\n",
    "duplicates = weather_hist[weather_hist.duplicated()]\n",
    "\n",
    "# Print the number of duplicate rows, if any\n",
    "num_duplicates = len(duplicates)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\n\")\n",
    "    print(f\"{num_duplicates} duplicate rows found in Weathe History Dataset.\")\n",
    "    print(\"\\n\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"No duplicate rows found in WeatherHistory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zq1ONxXXzooY",
    "outputId": "f2432898-a224-462d-cc2f-7ecb5711e543"
   },
   "outputs": [],
   "source": [
    "# Removing duplicated values\n",
    "weather_hist.drop_duplicates(inplace=True)\n",
    "# Again checking for duplicated values\n",
    "print(\"Duplicated Values: \", weather_hist.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4bVUXb6zyx3",
    "outputId": "33be1348-d3cf-4399-bcd6-5000620a4ac5"
   },
   "outputs": [],
   "source": [
    "#Printing the shape of dataset after deleting Duplicates\n",
    "print(\"Number of Columns in the Weather History Data frame:\", weather_hist.shape[1])\n",
    "print(\"Number of records in the Weather History data frame:\", weather_hist.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uma5ZXoBz4NV",
    "outputId": "dc4f190b-ff63-41fd-fbb9-ee600cd3751e"
   },
   "outputs": [],
   "source": [
    "# Checking missing values\n",
    "\n",
    "# Check for null values in the DataFrame\n",
    "null_values = weather_hist.isnull().sum()\n",
    "\n",
    "# Print the count of null values in each column\n",
    "print('Checking the NULL Values in  WeatherHistory Dataset..\\n')\n",
    "\n",
    "# Check if there are any null values\n",
    "if null_values.sum() == 0:\n",
    "    print(f'\\n There are no null values in the given dataset.')\n",
    "else:\n",
    "    columns_with_null_values = null_values[null_values > 0].index.tolist()\n",
    "    # Loop over the columns with null values and print the count of null values for each column\n",
    "    for column in columns_with_null_values:\n",
    "        count = null_values[column]\n",
    "        print(f\"Column '{column}' has {count} null values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WH39rXZqz8xQ",
    "outputId": "a35ffbd6-4abe-4e06-85d7-779980aeb0ed"
   },
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "weather_hist['Precip Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0NN-hjY0COv",
    "outputId": "e8912b3b-5942-4b0d-808a-db3a40556a5c"
   },
   "outputs": [],
   "source": [
    "# Remove rows with missing values in 'Precip Type' column\n",
    "weather_hist = weather_hist[(weather_hist['Precip Type'] != '?') & (weather_hist['Precip Type'] != '%')]\n",
    "\n",
    "# Verify the changes\n",
    "weather_hist['Precip Type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGdUpTQu1kIQ"
   },
   "outputs": [],
   "source": [
    "# Remove rows with null values in specified columns\n",
    "weather_hist = weather_hist.dropna(subset=['Precip Type', 'Wind Speed (km/h)', 'Visibility (km)', 'Pressure (millibars)'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YI9DKc0y4fhn",
    "outputId": "8f2fc7d1-8ac9-416f-ffde-64e5994f29b9"
   },
   "outputs": [],
   "source": [
    "# Re-check Handling Missing Values\n",
    "missing_values = weather_hist.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mqhtgqHK4lFv",
    "outputId": "64972d1b-ad47-4f3e-dc2c-aaf76d91361a"
   },
   "outputs": [],
   "source": [
    "#Printing the shape of dataset after deleting Duplicates\n",
    "print(\"Number of Columns in the Weather History Data frame:\", weather_hist.shape[1])\n",
    "print(\"Number of records in the Weather History data frame:\", weather_hist.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMiTi0r75N_8"
   },
   "outputs": [],
   "source": [
    "# Remove the 'Daily Summary' column from the DataFrame\n",
    "weather_hist = weather_hist.drop('Daily Summary', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XcfmeSQ45bY"
   },
   "source": [
    "\n",
    "Here are some reasons to justify deleting the 'Daily Summary' column from the entire dataset:\n",
    "\n",
    "Irrelevance for Analysis: The 'Daily Summary' column contains textual descriptions of daily weather summaries. If your analysis focuses more on numerical weather data (such as temperature, humidity, etc.) rather than descriptive summaries, keeping this column may not add value to your analysis.\n",
    "\n",
    "Reduced Memory Usage: Textual data can occupy more memory compared to numerical data. By removing the 'Daily Summary' column, you can reduce the overall memory usage of your dataset, which can be beneficial for large datasets or when working with memory-constrained environments.\n",
    "\n",
    "Simplicity and Focus: Removing irrelevant columns can simplify your dataset and focus your analysis on the key variables of interest. This can make your analysis more manageable and easier to interpret.\n",
    "\n",
    "Enhanced Performance: With fewer columns, operations on the dataset, such as calculations or transformations, may be faster and more efficient, leading to improved performance in data processing tasks.\n",
    "\n",
    "Consistency and Standardization: By removing a column that contains descriptive text, you can ensure that your dataset remains consistent in terms of data types (e.g., numeric data) and standardizes the format for easier processing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W72XCOc5pdbd",
    "outputId": "fe4966c2-0ad0-4727-b208-06b11e76295a"
   },
   "outputs": [],
   "source": [
    "# Define a dictionary mapping current weather summaries to new categories\n",
    "weather_mapping = {\n",
    "    'Clear': 'Clear Skies',\n",
    "    'Partly Cloudy': 'Cloudy Skies',\n",
    "    'Mostly Cloudy': 'Cloudy Skies',\n",
    "    'Overcast': 'Cloudy Skies',\n",
    "    'Foggy': 'Foggy Day',\n",
    "    'Breezy and Foggy': 'Foggy Day',\n",
    "    'Windy and Foggy': 'Foggy Day',\n",
    "    'Breezy': 'Breezy Day',\n",
    "    'Breezy and Mostly Cloudy': 'Breezy Day',\n",
    "    'Breezy and Partly Cloudy': 'Breezy Day',\n",
    "    'Breezy and Overcast': 'Breezy Day',\n",
    "    'Windy': 'Windy Day',\n",
    "    'Windy and Mostly Cloudy': 'Windy Day',\n",
    "    'Windy and Partly Cloudy': 'Windy Day',\n",
    "    'Windy and Overcast': 'Windy Day',\n",
    "    'Humid and Mostly Cloudy': 'Humid Day',\n",
    "    'Humid and Partly Cloudy': 'Humid Day',\n",
    "    'Humid and Overcast': 'Humid Day',\n",
    "    'Dry': 'Dry Day',\n",
    "    'Dry and Mostly Cloudy': 'Dry Day',\n",
    "    'Dry and Partly Cloudy': 'Dry Day',\n",
    "    'Light Rain': 'Rainy Day',\n",
    "    'Drizzle': 'Rainy Day',\n",
    "    'Rain': 'Rainy Day'\n",
    "}\n",
    "\n",
    "# Create a new column 'Weather Category' based on the mapping\n",
    "weather_hist['Summary'] = weather_hist['Summary'].map(weather_mapping)\n",
    "\n",
    "# Display the value counts of the new column\n",
    "print(weather_hist['Summary'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "me7qz0rk4sgX",
    "outputId": "3c79f154-b555-40a8-cd43-02256d67a1c6"
   },
   "outputs": [],
   "source": [
    "# Verify the changes\n",
    "weather_hist.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ltDdvIC7RGy",
    "outputId": "8661ba7a-9828-4a0f-cf38-82a9a457be15"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Define the format string for the date\n",
    "format_string = \"%Y-%m-%d %H:%M:%S.%f %z\"\n",
    "\n",
    "# Function to check if a value is in the correct format\n",
    "def check_date_format(value):\n",
    "    try:\n",
    "        datetime.strptime(value, format_string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Apply the function to each value in the 'Formatted Date' column and create a new column 'is_valid_date'\n",
    "weather_hist['is_valid_date'] = weather_hist['Formatted Date'].apply(check_date_format)\n",
    "\n",
    "# Filter the DataFrame to show only rows where 'is_valid_date' is False\n",
    "invalid_dates = weather_hist[~weather_hist['is_valid_date']]\n",
    "\n",
    "# Display the rows with invalid dates\n",
    "print(\"Rows with invalid dates:\")\n",
    "print(invalid_dates[['Formatted Date', 'is_valid_date']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "0DGH1_KG5vUA",
    "outputId": "5a0f1b5d-b276-46e5-ebc8-8f9e50c42ef5"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Label encode object columns\n",
    "object_columns = ['Summary', 'Precip Type']\n",
    "for col in object_columns:\n",
    "    weather_hist[col+'_encoded'] = label_encoder.fit_transform(weather_hist[col])\n",
    "\n",
    "# Convert 'Formatted Date' to datetime format with utc=True\n",
    "weather_hist['Formatted Date'] = pd.to_datetime(weather_hist['Formatted Date'], utc=True)\n",
    "\n",
    "# Extract year, month, day, and hour\n",
    "weather_hist['Year'] = weather_hist['Formatted Date'].dt.year\n",
    "weather_hist['Month'] = weather_hist['Formatted Date'].dt.month\n",
    "weather_hist['Day'] = weather_hist['Formatted Date'].dt.day\n",
    "weather_hist['Hour'] = weather_hist['Formatted Date'].dt.hour\n",
    "\n",
    "# Create dictionaries for mapping encoded values to original labels\n",
    "summary_mapping = dict(zip(weather_hist['Summary_encoded'], weather_hist['Summary']))\n",
    "precip_mapping = dict(zip(weather_hist['Precip Type_encoded'], weather_hist['Precip Type']))\n",
    "\n",
    "# Display the updated DataFrame and the mapping dictionaries\n",
    "print(\"Weather History DataFrame:\")\n",
    "weather_hist[['Summary', 'Precip Type', 'Summary_encoded', 'Precip Type_encoded', 'Year', 'Month', 'Day', 'Hour']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gX7DT0WNocOX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "id": "Kgwh6WnCE4iC",
    "outputId": "1036d872-4e92-4872-853b-78a56b738463"
   },
   "outputs": [],
   "source": [
    "weather_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4gWihDRE5b0",
    "outputId": "12dbf087-3bc4-4853-f4ba-db35e78449d6"
   },
   "outputs": [],
   "source": [
    "print(\"\\nSummary Mapping:\")\n",
    "\n",
    "summary_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ezx4WXUJEYs",
    "outputId": "2a9591d3-7c87-4c6c-c369-e349d591084c"
   },
   "outputs": [],
   "source": [
    "weather_hist['Summary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHskC-paE5gg",
    "outputId": "8f6e93a0-fbce-454c-c04e-c8fda7cd91c0"
   },
   "outputs": [],
   "source": [
    "print(\"\\nPrecip Type Mapping:\")\n",
    "\n",
    "\n",
    "precip_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-iiRpjeCm-T",
    "outputId": "0547d931-ae0f-4494-df04-566d0f5e9a8d"
   },
   "outputs": [],
   "source": [
    "# Assuming 'weather_hist' is your DataFrame\n",
    "\n",
    "# Use factorize to encode 'Summary' and 'Precip Type' columns\n",
    "weather_hist['Summary_encoded'], summary_mapping_index = weather_hist['Summary'].factorize()\n",
    "weather_hist['Precip Type_encoded'], precip_mapping_index = weather_hist['Precip Type'].factorize()\n",
    "\n",
    "# Display the mapping indexes\n",
    "print(\"Summary Mapping Index:\")\n",
    "print(summary_mapping_index)\n",
    "\n",
    "print(\"\\nPrecip Type Mapping Index:\")\n",
    "print(precip_mapping_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzmSI0tsDrIP",
    "outputId": "6b8e9ff8-ba5b-46e9-dc60-66bdc6cf2544"
   },
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "\n",
    "# Get the unique values in the 'Summary' column before encoding\n",
    "summary_unique_values = weather_hist['Summary'].unique()\n",
    "\n",
    "# Get the unique values in the 'Precip Type' column before encoding\n",
    "precip_unique_values = weather_hist['Precip Type'].unique()\n",
    "\n",
    "# Display the unique values\n",
    "print(\"Unique values in 'Summary' column before encoding:\")\n",
    "print(summary_unique_values)\n",
    "\n",
    "print(\"\\nUnique values in 'Precip Type' column before encoding:\")\n",
    "print(precip_unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "JYcYFdxqG8y9",
    "outputId": "a510bd8b-14bf-4958-d348-dc7093956e71"
   },
   "outputs": [],
   "source": [
    "# Drop original categorical columns\n",
    "weather_hist = weather_hist.drop(columns=['Summary', 'Precip Type', 'Formatted Date'])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"Encoded Weather History DataFrame:\")\n",
    "weather_hist.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdwLBWPr6eho",
    "outputId": "951d2ce0-4e4e-40b8-b2a1-fd1ff20ad0a9"
   },
   "outputs": [],
   "source": [
    "weather_hist['is_valid_date'].value_counts().get(False, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XrSDVP6iADCD",
    "outputId": "9270abbc-00ae-4668-d36f-a267e25d9e37"
   },
   "outputs": [],
   "source": [
    "weather_hist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "C0BYQuZ8BwbF",
    "outputId": "d530bf99-c8d6-49bb-e40d-94e946ff3756"
   },
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "columns_to_remove = ['is_valid_date']\n",
    "weather_hist = weather_hist.drop(columns=columns_to_remove)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "weather_hist.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "nWnvOkIrIGjs",
    "outputId": "0254bfcd-31f2-4de9-e236-5e0a03f346dc"
   },
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "weather_hist = weather_hist.rename(columns={'Summary_encoded': 'Summary', 'Precip Type_encoded': 'Precip Type'})\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"Updated Weather History DataFrame:\")\n",
    "weather_hist.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUIB4S5-BwiR",
    "outputId": "65ff09e9-228e-4cd9-bc63-93f65fe0ca62"
   },
   "outputs": [],
   "source": [
    "weather_hist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VThtunJJBwn6",
    "outputId": "39a66fe9-2d69-4352-9f58-63c0e7c79960"
   },
   "outputs": [],
   "source": [
    "missing_values = weather_hist.isnull().sum()\n",
    "print(\"Missing values:\")\n",
    "missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "FHi6iC7CBwss",
    "outputId": "afb95cc3-00a1-464a-f119-6469f2046267"
   },
   "outputs": [],
   "source": [
    "duplicate_rows = weather_hist[weather_hist.duplicated()]\n",
    "print(\"\\nDuplicate rows:\")\n",
    "duplicate_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrfbd0XEI6Xf",
    "outputId": "088ecb88-18b7-49ab-c6d9-f20f0190edf0"
   },
   "outputs": [],
   "source": [
    "null_values = weather_hist.isna().sum()\n",
    "print(\"\\nNull values:\")\n",
    "null_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUS1nSquuybN",
    "outputId": "3bbd63c4-47af-40d3-966a-12c20f955c0d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Assuming weather_hist is your DataFrame containing the dataset\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = weather_hist.drop(['Summary'], axis=1)\n",
    "y = weather_hist['Summary']\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_encoded_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lC6mrzqG1JnR",
    "outputId": "71b9813a-0691-4c28-e3ed-6e5a076bef92"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Predict on train and test sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_train_pred_labels = label_encoder.inverse_transform(y_train_pred.argmax(axis=1))\n",
    "y_test_pred_labels = label_encoder.inverse_transform(y_test_pred.argmax(axis=1))\n",
    "y_train_true_labels = label_encoder.inverse_transform(y_train.argmax(axis=1))\n",
    "y_test_true_labels = label_encoder.inverse_transform(y_test.argmax(axis=1))\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train_true_labels, y_train_pred_labels)\n",
    "test_accuracy = accuracy_score(y_test_true_labels, y_test_pred_labels)\n",
    "\n",
    "# Generate confusion matrix and classification report\n",
    "train_conf_matrix = confusion_matrix(y_train_true_labels, y_train_pred_labels)\n",
    "test_conf_matrix = confusion_matrix(y_test_true_labels, y_test_pred_labels)\n",
    "\n",
    "train_classification_report = classification_report(y_train_true_labels, y_train_pred_labels)\n",
    "test_classification_report = classification_report(y_test_true_labels, y_test_pred_labels)\n",
    "\n",
    "# Print the results\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2MxpJwgP3hKC",
    "outputId": "c9c7d324-8672-4b34-b48d-6b8951c0b5e8"
   },
   "outputs": [],
   "source": [
    "print(\"\\nTrain Confusion Matrix:\")\n",
    "train_conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMIHZXOt5VVk",
    "outputId": "c7a17940-b39a-4fd3-85d3-0614bcad3b2c"
   },
   "outputs": [],
   "source": [
    "print(\"\\nTest Confusion Matrix:\")\n",
    "test_conf_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aaUOjyJ75anx",
    "outputId": "f688ff0f-7630-4893-9609-dc70bb314a70"
   },
   "outputs": [],
   "source": [
    "print(\"\\nTrain Classification Report:\")\n",
    "print(train_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvp4qV185cHT",
    "outputId": "13b61058-2728-41ce-d708-04d7060f8643"
   },
   "outputs": [],
   "source": [
    "print(\"\\nTest Classification Report:\")\n",
    "print(test_classification_report)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
